# Implementing a Neural Network

This repository contains a neural network implemented using **jupyter** and **numpy**, together with several notebooks guiding through the process of its development.

<hr>
# Interactive plots:

In order to be able to visualize the plotly graphs, you need to access the notebooks from *nbviewer*.

* [01 Neural Networks - Logic Gates and Feed Fordward](http://nbviewer.jupyter.org/github/pablobordons/neural_network/blob/master/01_logic_gates.ipynb)

* [02 Neural Networks - Backpropagation](http://nbviewer.jupyter.org/github/pablobordons/neural_network/blob/master/02_backpropagation.ipynb)

* [03 Neural Networks - ANN basic class](http://nbviewer.jupyter.org/github/pablobordons/neural_network/blob/master/03_ANN_basic.ipynb)

* [04 Neural Networks - ANN and MNIST](http://nbviewer.jupyter.org/github/pablobordons/neural_network/blob/master/04_ANN.ipynb)

<br>
# Script

In order to run the script (and the noteboks regarding MNIST) you need to store the MNIST dataset in a directory called 'data' contained in the same directory of the scripts and/or the notebooks.

The script can be called from the comand line and it loads the data set and trains a neural network over it, achieving 90% of accuracy over the test set with the specified parameters.

The output of the script is as follows:

![script output](script_output.png?raw=true "Script Output")
<hr>
